{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7b7a3c",
   "metadata": {},
   "source": [
    "# Fitting the Keeling Curve\n",
    "\n",
    "Gareth Funning, University of California, Riverside\n",
    "\n",
    "This is an exercise in curve fitting to a classic Earth Science dataset $-$ the contemporary CO$_2$ record from Mauna Loa, [as first measured by Charles David Keeling in 1958](https://keelingcurve.ucsd.edu/). This record, showing an accelerating increase in carbon dioxide concentrations in the Earth's atmosphere through the late 20th and early 21st Centuries, was famously shown by Al Gore in his movie [An Inconvenient Truth](https://en.wikipedia.org/wiki/An_Inconvenient_Truth) as part of his call to act to reduce carbon emissions and prevent extreme global warming. We will download the data, plot it up, and try to fit various functions to it. \n",
    "\n",
    "This is also an opportunity to get to know Jupyter notebooks and to learn and use the Markdown syntax. These are very helpful for running authentic codes and scripts, and displaying and explaining results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe8181",
   "metadata": {},
   "source": [
    "## 0. Introduction to Jupyter and Markdown\n",
    "\n",
    "[Jupyter](https://docs.jupyter.org/en/latest/) was developed as a platform for running authentic codes in a web browser, alongside explanatory text, figures and graphical output. It is most commonly associated with Python codes, but supports over 40 programming languages, including Julia and R (representing the \"Ju\" and \"r\" in \"Jupyter\", respectively, alongside the \"pyt\" for Python). I will briefly describe a few elements of Jupyter before we get stuck into actually using it...\n",
    "\n",
    "### 0.1 Notebooks\n",
    "\n",
    "The basic unit of Jupyter computing is the **Jupyter notebook**. This is a document that renders as a webpage, including snippets of code (contained in so-called **code cells**) and areas of formatted text, embedded images and links (contained in so-called **Markdown cells**). This document is one, of course (and this text, with its hierarchical headings and boldface text) is in a Markdown cell). The contents of each cell need to be executed in order for them to do anything. You can do this by slicking the 'Run' button  on the toolbar at the top of the window, or by pressing Shift+Enter on the keyboard.\n",
    "\n",
    "Notebook files have the suffix `.ipynb`, short for 'iPython notebook' (iPython being the 'old' name for Jupyter notebooks, short for 'interactive Python'). All of the elements, the code, text and any graphical output, are saved in one file. \n",
    "\n",
    "### 0.2 Code cells\n",
    "\n",
    "Code cells are cells in which you can write and execute code. You can select which type of cell you have from the drop-down list on the toolbar. Each code cell can contain a section of a program (Python, by default), and they need not be executed all at once. One difference with a regular Python program would be the mode of execution. While a Python program will typically run from beginning to end without interruptions, you can execute code cells one by one, and view and/or plot the outcome at each step, which can be especially helpful for debugging.\n",
    "\n",
    "All the variables and arrays that you initiate in the notebook will be retained from one code cell to the next, so there is effectively no penalty to splitting up your code like that.\n",
    "\n",
    "\n",
    "### 0.3 Markdown and Markdown cells\n",
    "\n",
    "Markdown is a formatted text syntax that is used to render clean-looking hierarchical text, headings and graphics. The syntax is pretty easy to use, and it shares some similarities with LaTeX (such as its capabilities of rendering simple equations). It is documented here: https://www.markdownguide.org/basic-syntax/ \n",
    "\n",
    "Markdown has its own cells in Jupyter. This is one of them! It can be quite instructive to see what is in a Markdown cell 'behind the scenes', as it were. If you double-click on the cell, all will be revealed! Then, to restore the more pleasant text rendering, you can run the Markdown cell in the same way you would run a code cell $-$ click on 'Run' or hit Shift+Enter. \n",
    "\n",
    "### 0.4 The kernel\n",
    "\n",
    "Underpinning everything in Jupyter is the 'kernel' $-$ effectively a virtual machine in which the code, data and variables associated with a notebook are stored. This will keep running until it is stopped, or the user shuts down their Jupyter server. A few things to note: 1) if you keep opening notebooks without properly shutting down old kernels, you will start to eat into your system resources; 2) if your code crashes, or gets out of control, it will be somewhat comparmentilized $-$ you will be able to shutdown and restart the kernel without it crashing everything else.\n",
    "\n",
    "In this exercise, we are going to use the default kernel, which is the Python kernel. If you want to use other programming languages (e.g. Julia), then you will need to install (and/or compile) kernels for those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e5596",
   "metadata": {},
   "source": [
    "## 1. Dependencies\n",
    "\n",
    "This is where we initialize the Python packages we are going to use $-$ [numpy](https://numpy.org/doc/stable/reference/index.html#reference) and [pygmt](https://www.pygmt.org/latest/gallery/index.html). If you are not in the correct conda environment (i.e. the environment for the course), you might see some error messages here... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages we want by running this code cell\n",
    "import numpy as np\n",
    "import pygmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47321f7f",
   "metadata": {},
   "source": [
    "## 2. Download and prepare the data\n",
    "\n",
    "Download the data from the Scripps CO$_2$ website: https://scrippsco2.ucsd.edu/data/atmospheric_co2/primary_mlo_co2_record.html **The next thing is to look at the data and try and figure out how to 1) prepare it and 2) ingest it into Python in this notebook.**\n",
    "\n",
    "I'm not going to tell you how to do this part.\n",
    "\n",
    "**One hint:** starting a line with an exclamation point in a code cell allows you to run shell commands.\n",
    "\n",
    "**Another hint:** the data will often have header lines as well as gaps that you don't want to load in. There are also more columns in these files than we want $-$ we just want the date, in a friendly format, as well as the raw CO$_2$ record. So extract only those things. \n",
    "\n",
    "**A third hint:** the Python command `np.loadtxt` (e.g. here: https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html#numpy.loadtxt)  will help you to load text files into Python and your notebook.\n",
    "\n",
    "**A final hint:** the command `whos`, run on its own in a code cell will tell you all of the variables and arrays that are live in your current kernel. If you know MATLAB, you might recognize it. It can be very useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example\n",
    "\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this blank code cell is waiting for you to fill in!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783ea41",
   "metadata": {},
   "source": [
    "## 3. Plot the data\n",
    "\n",
    "**The next thing to do, which is always good practice, is to plot the things you just loaded in.** We can use PyGMT for this. PyGMT maintains almost all of the capabilities and has many similarities in syntax with regular, command-line GMT, but in a slightly fancier Python-based form. \n",
    "\n",
    "I am not going to give you all the details here either, but you can get a long way by looking at the examples and online help pages for PyGMT (e.g. for instance, here: https://www.pygmt.org/latest/gallery/index.html), as well as this little code snippet that is a good starting point that you can build on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235343b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a code snippet for plotting input data. you will probably need to modify it\n",
    "region = [1955, 2055, 300, 500]\n",
    "fig = pygmt.Figure()\n",
    "fig.basemap(region=region,projection='X15c',frame=True)\n",
    "fig.plot(x=data[:,0],y=data[:,1],style='c0.1c',fill='black')\n",
    "#fig.plot(x=data[:,0],y=synth_data,pen='2p,red')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is another nice, blank code cell for you...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed04cc",
   "metadata": {},
   "source": [
    "## 4. Fit a straight line to the data\n",
    "\n",
    "The simplest 'model' we can fit to the data is a straight line, which is a good excuse to show off my mastery of equation syntax in Markdown:\n",
    "\n",
    "$$y = mx +c$$\n",
    "\n",
    "Really, of course we want to solve this as a sequence of simultaneous equations, i.e.\n",
    "\n",
    "$$y_1 = mx_1 + c \\\\\n",
    "  y_2 = mx_2 + c \\\\ \n",
    "  y_3 = mx_3 + c \\\\ \n",
    "  \\ldots $$\n",
    "  \n",
    "for as many data points with $x$ and $y$ values as you have. In the case of the Mauna Loa CO$_2$ data, it's quite a lot.\n",
    "\n",
    "If you can form appropriate matrices, ${\\bf A}$ and ${\\bf d}$, then you can solve for model parameters ${\\bf m}$ by forming the normal equations and inverting them:\n",
    "\n",
    "$${\\bf A~m} = {\\bf d} \\\\\n",
    "  {\\bf A^T A~m} = {\\bf A^T d}\\\\\n",
    "  ({\\bf A^T A})^{-1} {\\bf A^T A~m} = ({\\bf A^T A})^{-1}{\\bf A^T d} $$\n",
    "  \n",
    "which simplifies to:\n",
    "\n",
    "$${\\bf m} = ({\\bf A^T A})^{-1}{\\bf A^T d} $$\n",
    "\n",
    "So, **I would like you to calculate the best-fitting straight line to the Mauna Loa CO$_2$ data**. I provide a code snippet below that can do the inversion part. I leave it to you to build the matrices and vectors.\n",
    "\n",
    "**One hint**: if you need to transpose a matrix, adding `.T` to its variable name will do that. Similarly, adding `.reshape(-1, 1)` to a regular numpy row vector will make it a column vector. \n",
    "\n",
    "**Another hint**: `np.vstack` and `np.hstack` are useful commands for building matrices (a.k.a. 2D arrays) out of numpy vectors. `np.ones` will make a vector of ones. `np.shape` will tell you the dimensions of a numpy array. It might be helpful to look through the numpy documentation: https://numpy.org/doc/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is another nice, blank code cell for you...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will complete the inversion, for a properly set up matrix A\n",
    "# and vector d...\n",
    "\n",
    "# construct the normal equations in matrix form\n",
    "ATA=np.matmul(A.T,A)\n",
    "ATd=np.matmul(A.T,d)\n",
    "\n",
    "# invert ATA and multiply that by ATd\n",
    "m=np.matmul(np.linalg.inv(ATA),ATd)\n",
    "\n",
    "# calculate the forward model (a.k.a. synthetic data) for your model parameters\n",
    "synth_data=np.matmul(A,m).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f34156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this lovely blank code cell to plot the data fit...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f22b2",
   "metadata": {},
   "source": [
    "## 5. Project your model into the future\n",
    "\n",
    "Many climate projections run to 2100, maybe because it's just far enough into the future that the climate could be really different by then. Anyway, by retaining your model parameters ${\\bf m}$ you can calculate CO$_2$ values for whenevey you want, so long as you build an ${\\bf A}$ matrix for the date range you want. \n",
    "\n",
    "So why don't you do that? **Calculate and then plot the CO$_2$ line out to 2100.** One useful snippet is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec787a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will make you a long vector of annual dates that you can \n",
    "# use to project your model to 2100\n",
    "long_dates=np.arange(1955,2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is another nice, blank code cell for you...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584f69c",
   "metadata": {},
   "source": [
    "## 7. Fit a parabola to the data\n",
    "\n",
    "Maybe the straight line is not the most realistic model? A parabola, which is the output of a quadratic function, might be much more appropriate?\n",
    "\n",
    "In this case, the equations we are trying to solve are of the form\n",
    "\n",
    "$$y_1 = ax_1 ^2 + bx_1 + c \\\\\n",
    "  y_2 = ax_2 ^2 + bx_2 + c \\\\ \n",
    "  y_3 = ax_3 ^2 + bx_2 +c \\\\ \n",
    "  \\ldots $$\n",
    "\n",
    "which implies something will have to change in the ${\\bf A}$ matrix at the very least...\n",
    "\n",
    "**Compute the best fitting parabola, and use it to project CO$_2$ levels out to 2100.**\n",
    "\n",
    "**A hint**: calculations might start to get a bit unstable with the large values involved in such a model. It might be sensible to subtract a constant from all of the dates used in this modeling effort, to make the numbers smaller. So long as you keep track of what that number is, and don't use the modified dates for plotting, it should be fine!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is another nice, blank code cell for you...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd553e49",
   "metadata": {},
   "source": [
    "## 8. Build higher-order polynomial models and project those, too\n",
    "\n",
    "Now you are probably getting the hang of this? One more task to put all of this together:\n",
    "\n",
    "**Fit, using the same method introduced above, models from a first-order polynomial function (power of $x^1$) up to a fifth-order polynomial (power of $x^5$), and plot all of them on a single plot. Then comment on the suitability of these different 'models' for projecting future CO$_2$ levels.**\n",
    "\n",
    "**Hint**: If you want to export any of your results to text files for plotting purposes (e.g. in regular GMT), then the `np.savetxt` command is good for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa97576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank code cell, innit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07835f",
   "metadata": {},
   "source": [
    "### Thoughts on the suitability of polynomial functions for projecting future CO$_2$ levels\n",
    "\n",
    "This is a place to share any thoughts you might have... delete this text and write your own..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c5fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
